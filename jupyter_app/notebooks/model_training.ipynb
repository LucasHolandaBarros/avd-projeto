{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2c47e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ajuste o caminho do CSV tratado e do diretório onde salvar modelos/artefatos\n",
    "FILE_PATH = r\"C:\\Users\\euque\\OneDrive\\Documentos\\Cesar School\\5° Período - CC Cesar School\\Análise e Visualização de Dados\\avd-projeto\\data\\processed\\concatenado_clean_20251125_202250.csv\"  \n",
    "ARTIFACT_DIR = r\"C:\\Users\\euque\\OneDrive\\Documentos\\Cesar School\\5° Período - CC Cesar School\\Análise e Visualização de Dados\\avd-projeto\\data\\artifacts\"\n",
    "\n",
    "import os\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "\n",
    "# Configure MLflow tracking URI (update env var or keep default)\n",
    "mlflow_tracking = os.getenv('MLFLOW_TRACKING_URI', 'http://mlflow:5000')\n",
    "mlflow.set_tracking_uri(mlflow_tracking)\n",
    "print('MLflow tracking URI:', mlflow.get_tracking_uri())\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(FILE_PATH, parse_dates=['DATA'], dayfirst=True, low_memory=False)\n",
    "display(df.head())\n",
    "\n",
    "# Select features and target\n",
    "EXTRA_COLUMNS = ['ESTACAO','DATA','HORA_UTC']\n",
    "FEATURES = ['TEMPERATURA_BULBO_SECO', 'PRESSAO_ATM_EST', 'RADIACAO_GLOBAL']\n",
    "TARGET = 'UMIDADE_REL'\n",
    "\n",
    "# Basic dropna for chosen columns\n",
    "df_model = df[FEATURES + [TARGET]].dropna()\n",
    "df_model[EXTRA_COLUMNS] = df.loc[df_model.index, EXTRA_COLUMNS]\n",
    "print('Used rows:', df_model.shape[0])\n",
    "\n",
    "X = df_model[FEATURES].values\n",
    "y = df_model[TARGET].values\n",
    "\n",
    "# Train-test split by time or random\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "\n",
    "# Train and evaluate\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print('MAE (test):', mae)\n",
    "\n",
    "\"\"\" Teste MLFLOW\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name='rf_umidade'):\n",
    "    mlflow.log_param('model', 'RandomForestRegressor')\n",
    "    mlflow.log_param('features', FEATURES)\n",
    "    mlflow.log_metric('mae', float(mae))\n",
    "    # save model artifact and log\n",
    "    model_path = os.path.join(ARTIFACT_DIR, 'rf_model.pkl')\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path='models')\n",
    "    # optional: save a small CSV with test set and predictions\n",
    "    out_df = pd.DataFrame(X_test, columns=FEATURES)\n",
    "    out_df[TARGET + '_real'] = y_test\n",
    "    out_df[TARGET + '_pred'] = preds\n",
    "    preds_path = os.path.join(ARTIFACT_DIR, 'predictions_partial.csv')\n",
    "    out_df.to_csv(preds_path, index=False)\n",
    "    mlflow.log_artifact(preds_path, artifact_path='predictions')\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print('MLflow run_id:', run_id) \"\"\"\n",
    "\n",
    "# Save final predictions (full set) to ARTIFACT_DIR for Power BI use (optional)\n",
    "# Predict on the whole dataset and export\n",
    "full_preds = pipeline.predict(df_model[FEATURES])\n",
    "df_out = df_model.copy()\n",
    "df_out[TARGET + '_pred'] = full_preds\n",
    "final_predictions_path = os.path.join(ARTIFACT_DIR, 'predictions_full.csv')\n",
    "df_out.to_csv(final_predictions_path, index=False)\n",
    "print('Predictions exported to', final_predictions_path)\n",
    "\n",
    "# Save model locally as well\n",
    "joblib.dump(pipeline, os.path.join(ARTIFACT_DIR, 'rf_model_for_serving.pkl'))\n",
    "print('Model saved in', ARTIFACT_DIR)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
